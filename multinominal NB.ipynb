{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "import random\n",
    "from prettytable import PrettyTable\n",
    "import textwrap \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import excel with pandas Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_emotions = pd.read_excel('Diabetes-classification.xlsx', sheet_name ='Emotions')\n",
    "\n",
    "# Preparing dataset\n",
    "x_emotion = df_emotions.loc[:,'discussion_text']\n",
    "y_emotion = df_emotions.loc[:,'Label']\n",
    "# removes all duplicates from list \n",
    "Labels_emotion = list(dict.fromkeys(y_emotion)) \n",
    "# puts discussion_text to a str and tokenize it\n",
    "raw_text_emotion = df_emotions['discussion_text'].str.cat()\n",
    "tokens_emotion = nltk.word_tokenize(raw_text_emotion)\n",
    "text_emotion = nltk.Text(tokens_emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinominal NB classifer for Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anticipation\n",
      "Surprise\n",
      "+------------------------------------------+--------------+\n",
      "|             Discussion text              |   Emotion    |\n",
      "+------------------------------------------+--------------+\n",
      "| If,that's,the,case,,insulin,deficiency,i | Anticipation |\n",
      "| sn't,their,problem,,so,more,insulin,shou |              |\n",
      "| ldn't,be,the,solution..,Adding,insulin,i |              |\n",
      "| s,no,way,to,deal,with,insulin,resistance |              |\n",
      "| ,,it's,just,throwing,fuel,on,the,fire.., |              |\n",
      "| Type,2,diabetes,is,characterized,by,insu |              |\n",
      "| lin,resistance,actually,,and,that's,very |              |\n",
      "|                 ,widely                  |              |\n",
      "|                                          |              |\n",
      "|                                          |              |\n",
      "| I,recorded,the,programme,and,finally,wat |   Surprise   |\n",
      "| ched,it,last,night..,I,was,annoyed,that, |              |\n",
      "| he,kept,saying,that,T2,diabetes,is,due,t |              |\n",
      "| o,lifestyle,choice,when,the,experience,o |              |\n",
      "| f,forum,members,here,prove,that,it,clear |              |\n",
      "| ly,is,not,-,from,my,own,perspective,my,g |              |\n",
      "| randfather,,mother,and,brother,had/have  |              |\n",
      "|                                          |              |\n",
      "|                                          |              |\n",
      "+------------------------------------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "# the reviews will be stored as document pairs of words and category\n",
    "X_list_of_words = [sentence.split(\" \") for sentence in x_emotion]\n",
    "documents = list(zip(X_list_of_words, y_emotion))\n",
    "\n",
    "#give random order to the documents\n",
    "random.shuffle(documents)\n",
    "\n",
    "tab = PrettyTable(['Discussion text', 'Emotion'])\n",
    "tab.horizontal_char = '-'\n",
    "\n",
    "for (doc, cat) in documents[0:2]:\n",
    "    feats = textwrap.fill(','.join(doc[:50]), width=40)\n",
    "    tab.add_row([ feats, cat])\n",
    "    tab.add_row([ '\\n', '\\n'])\n",
    "    print(cat)\n",
    "\n",
    "print(tab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words from emotion corpus:  276377\n",
      "most freq words:  [('think', 398), ('other', 398), ('does', 393), ('many', 389), ('only', 387), ('day', 385), ('time', 383), ('much', 380), ('help', 379), ('risk', 376)]\n",
      "word_features[:25]:  ['i', '..', 'and', 'the', 'to', 'a', 'of', 'diabetes', '2', 'type', 'is', 'my', 'that', 'have', 'in', 'it', 'with', 'for', 'you', 'was', 'on', 'as', 'not', 'but', ')']\n"
     ]
    }
   ],
   "source": [
    "print('total words from emotion corpus: ', len(text_emotion))\n",
    "\n",
    "# load all the words in freq distribution\n",
    "all_words = nltk.FreqDist(w.lower() for w in text_emotion)\n",
    "\n",
    "#construct a list of the 2000 most frequent words in the overall corpus (you can try with other numbers as well)\n",
    "most_freq_words = all_words.most_common(3000)\n",
    "print('most freq words: ', most_freq_words[100:110])\n",
    "\n",
    "word_features = [word for (word, count) in most_freq_words]\n",
    "print('word_features[:25]: ', word_features[:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed document features, printing the first 25 features \n",
      "\n",
      " {'contains(i)': True, 'contains(..)': True, 'contains(and)': True, 'contains(the)': True, 'contains(to)': True, 'contains(a)': True, 'contains(of)': True, 'contains(diabetes)': True, 'contains(2)': True, 'contains(type)': True, 'contains(is)': True, 'contains(my)': True, 'contains(that)': True, 'contains(have)': True, 'contains(in)': True, 'contains(it)': True, 'contains(with)': True, 'contains(for)': True, 'contains(you)': True, 'contains(was)': True, 'contains(on)': True, 'contains(as)': True, 'contains(not)': True, 'contains(but)': True, 'contains())': True}\n"
     ]
    }
   ],
   "source": [
    "def get_document_features(document, doc_features):\n",
    "    \"\"\"\n",
    "        This function will convert given document into a feature set.\n",
    "        Note that we need to add the feature set that is relevant to the document we are inputting\n",
    "        \n",
    "    \"\"\"\n",
    "    #checking whether a word occurs in a set is much faster than checking whether it occurs in a list \n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    \n",
    "    #the feaures dict will consist of words as keys and boolean value of whether they exist in the document\n",
    "    for word in doc_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "\n",
    "# test code for the above function\n",
    "#words_doc = movie_reviews.words('pos/cv957_8737.txt')\n",
    "words_doc = text_emotion\n",
    "\n",
    "feat_dict = get_document_features(words_doc, word_features)\n",
    "\n",
    "feat_dict_25 = {k: feat_dict[k] for k in list(feat_dict.keys())[:25]}\n",
    "print('transformed document features, printing the first 25 features \\n\\n', feat_dict_25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "Most Informative Features\n",
      "         contains(bacon) = True            Anger : Trust  =     22.5 : 1.0\n",
      "          contains(hold) = True            Anger : Trust  =     22.5 : 1.0\n",
      "    contains(production) = True            Anger : Trust  =     22.5 : 1.0\n",
      "          contains(rare) = True            Anger : Trust  =     22.5 : 1.0\n",
      "         contains(shift) = True            Anger : Trust  =     22.5 : 1.0\n",
      "            contains(38) = True             Fear : Trust  =     20.7 : 1.0\n",
      "            contains(ie) = True             Fear : Trust  =     20.7 : 1.0\n",
      "           contains(2nd) = True            Anger : Antici =     18.0 : 1.0\n",
      "         contains(story) = True            Anger : Antici =     18.0 : 1.0\n",
      "        contains(stated) = True           Surpri : Trust  =     17.7 : 1.0\n",
      "  contains(intervention) = True             Fear : Antici =     16.6 : 1.0\n",
      "            contains(bc) = True             Fear : Trust  =     14.8 : 1.0\n",
      "         contains(crazy) = True             Fear : Trust  =     14.8 : 1.0\n",
      "          contains(lock) = True             Fear : Trust  =     14.8 : 1.0\n",
      "        contains(skinny) = True             Fear : Trust  =     14.8 : 1.0\n",
      "      contains(speaking) = True             Fear : Trust  =     14.8 : 1.0\n",
      "       contains(suppose) = True             Fear : Trust  =     14.8 : 1.0\n",
      "       contains(systems) = True             Fear : Trust  =     14.8 : 1.0\n",
      "          contains(seek) = True           Surpri : Antici =     14.2 : 1.0\n",
      "         contains(vegan) = True           Surpri : Antici =     14.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "#obtain feature sets for all movie reviews\n",
    "featuresets = [(get_document_features(d,word_features), c) for (d,c) in documents]\n",
    "\n",
    "#split into train and test set (you can experiment with distribution here) 100 - 100 og\n",
    "train_set, test_set = featuresets[200:], featuresets[:100]\n",
    "\n",
    "#instantiate classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "#print accuracy and most informative features\n",
    "print(nltk.classify.accuracy(classifier, test_set)) \n",
    "\n",
    "classifier.show_most_informative_features(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of sample review:  Joy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_review = \"I think i got rid of my sickness and feel happy\"\n",
    "\n",
    "#get features specific to the input text\n",
    "sample_features = {word:True for word in sample_review.split()}\n",
    "\n",
    "\n",
    "sample_review_doc_feats = get_document_features(sample_review.split(),sample_features)\n",
    "\n",
    "\n",
    "#print('Sample review features: \\n\\n',sample_review_doc_feats)\n",
    "\n",
    "print('result of sample review: ', classifier.classify(sample_review_doc_feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loads in Patient Journey labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_patient = pd.read_excel('Diabetes-classification.xlsx', sheet_name='Patient-journey') # Reads in excel\n",
    "\n",
    "# Preparing dataset\n",
    "x_journey = df_patient.loc[:,'discussion_text']\n",
    "y_journey = df_patient.loc[:,'Label']\n",
    "# removes all duplicates from list \n",
    "Labels_journey = list(dict.fromkeys(y_journey)) \n",
    "# puts discussion_text to a str and tokenize it\n",
    "raw_text_journey = df_patient['discussion_text'].str.cat()\n",
    "tokens_journey = nltk.word_tokenize(raw_text_journey)\n",
    "text_journey = nltk.Text(tokens_journey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinical Treatment\n",
      "Clinical Treatment\n",
      "+------------------------------------------+--------------------+\n",
      "|             Discussion text              |      Emotion       |\n",
      "+------------------------------------------+--------------------+\n",
      "| Here,is,a,link,to,a,chart,that,explains, | Clinical Treatment |\n",
      "| the,different,oral,meds,used,to,treat,Ty |                    |\n",
      "| pe,2,Diabetes:,http://www.joslin.org/inf |                    |\n",
      "| o/oral_diabetes_medications_summary_char |                    |\n",
      "| t.html,You,will,most,likely,be,started,o |                    |\n",
      "| n,metformin..,If,you,are,worried,about,s |                    |\n",
      "| tomach,issues,,ask,for,the,extended,rele |                    |\n",
      "|         ase,(ER),version..,Carol         |                    |\n",
      "|                                          |                    |\n",
      "|                                          |                    |\n",
      "| Health,care,professionals,who,are,intere | Clinical Treatment |\n",
      "| sted,in,educating,the,public,about,both, |                    |\n",
      "| Type,I,and,Type,2,diabetes,should,be,pro |                    |\n",
      "| active,in,promoting,breastfeeding..,Whil |                    |\n",
      "| e,nothing,is,a,guarantee,,breastfeeding, |                    |\n",
      "| provides,protection,for,children,and,the |                    |\n",
      "| ir,mothers,against,diabetes..,There,is,s |                    |\n",
      "|   ignificant,research,to,back,this,up.   |                    |\n",
      "|                                          |                    |\n",
      "|                                          |                    |\n",
      "+------------------------------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# the reviews will be stored as document pairs of words and category\n",
    "X_list_of_words_journey = [sentence.split(\" \") for sentence in x_journey]\n",
    "documents_journey = list(zip(X_list_of_words_journey, y_journey))\n",
    "\n",
    "#give random order to the documents\n",
    "random.shuffle(documents_journey)\n",
    "\n",
    "tab = PrettyTable(['Discussion text', 'Emotion'])\n",
    "tab.horizontal_char = '-'\n",
    "\n",
    "for (doc, cat) in documents_journey[0:2]:\n",
    "    feats = textwrap.fill(','.join(doc[:50]), width=40)\n",
    "    tab.add_row([ feats, cat])\n",
    "    tab.add_row([ '\\n', '\\n'])\n",
    "    print(cat)\n",
    "\n",
    "print(tab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words from emotion corpus:  116721\n",
      "most freq words:  [('his', 165), ('exercise', 165), ('only', 159), ('she', 159), ('time', 159), ('well', 157), ('any', 157), ('glucose', 156), ('then', 155), ('disease', 154)]\n",
      "word_features[:25]:  ['..', 'i', 'and', 'the', 'to', 'a', 'of', 'diabetes', '2', 'type', 'is', 'in', 'my', 'that', 'with', 'have', 'for', 'it', 'you', 'was', 'on', 'as', 'are', ')', '.']\n"
     ]
    }
   ],
   "source": [
    "print('total words from emotion corpus: ', len(text_journey))\n",
    "\n",
    "# load all the words in freq distribution\n",
    "all_words_journey = nltk.FreqDist(w.lower() for w in text_journey)\n",
    "\n",
    "#construct a list of the 2000 most frequent words in the overall corpus (you can try with other numbers as well)\n",
    "most_freq_words_journey = all_words_journey.most_common(6000)\n",
    "print('most freq words: ', most_freq_words_journey[100:110])\n",
    "\n",
    "word_features_journey = [word for (word, count) in most_freq_words_journey]\n",
    "print('word_features[:25]: ', word_features_journey[:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed document features, printing the first 25 features \n",
      "\n",
      " {'contains(i)': True, 'contains(..)': True, 'contains(and)': True, 'contains(the)': True, 'contains(to)': True, 'contains(a)': True, 'contains(of)': True, 'contains(diabetes)': True, 'contains(2)': True, 'contains(type)': True, 'contains(is)': True, 'contains(my)': True, 'contains(that)': True, 'contains(have)': True, 'contains(in)': True, 'contains(it)': True, 'contains(with)': True, 'contains(for)': True, 'contains(you)': True, 'contains(was)': True, 'contains(on)': True, 'contains(as)': True, 'contains(not)': True, 'contains(but)': True, 'contains())': True}\n"
     ]
    }
   ],
   "source": [
    "def get_document_features_journey(documents_journey, doc_features):\n",
    "    \"\"\"\n",
    "        This function will convert given document into a feature set.\n",
    "        Note that we need to add the feature set that is relevant to the document we are inputting\n",
    "        \n",
    "    \"\"\"\n",
    "    #checking whether a word occurs in a set is much faster than checking whether it occurs in a list \n",
    "    document_words = set(documents_journey)\n",
    "    features = {}\n",
    "    \n",
    "    #the feaures dict will consist of words as keys and boolean value of whether they exist in the document\n",
    "    for word in doc_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "\n",
    "# test code for the above function\n",
    "#words_doc = movie_reviews.words('pos/cv957_8737.txt')\n",
    "words_doc = text_journey\n",
    "\n",
    "feat_dict = get_document_features(words_doc, word_features_journey)\n",
    "\n",
    "feat_dict_25 = {k: feat_dict[k] for k in list(feat_dict.keys())[:25]}\n",
    "print('transformed document features, printing the first 25 features \\n\\n', feat_dict_25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41\n",
      "Most Informative Features\n",
      "      contains(exercise) = True           Living : Living =     45.0 : 1.0\n",
      "    contains(colleagues) = True           Altern : Living =     42.0 : 1.0\n",
      "    contains(treatments) = True           Altern : Living =     35.0 : 1.0\n",
      "            contains(35) = True           Altern : Living =     30.0 : 1.0\n",
      "        contains(acidic) = True           Altern : Living =     30.0 : 1.0\n",
      "    contains(additional) = True           Altern : Living =     30.0 : 1.0\n",
      "         contains(adobe) = True           Altern : Living =     30.0 : 1.0\n",
      "        contains(agents) = True           Altern : Living =     30.0 : 1.0\n",
      "        contains(bitter) = True           Altern : Living =     30.0 : 1.0\n",
      "        contains(bought) = True           Altern : Living =     30.0 : 1.0\n",
      "        contains(called) = True           Altern : Living =     30.0 : 1.0\n",
      "    contains(conclusion) = True           Altern : Living =     30.0 : 1.0\n",
      "   contains(development) = True           Altern : Living =     30.0 : 1.0\n",
      "      contains(download) = True           Altern : Living =     30.0 : 1.0\n",
      "       contains(embrace) = True           Altern : Living =     30.0 : 1.0\n",
      "      contains(examined) = True           Altern : Living =     30.0 : 1.0\n",
      "       contains(failing) = True           Altern : Living =     30.0 : 1.0\n",
      "          contains(file) = True           Altern : Living =     30.0 : 1.0\n",
      "          contains(guys) = True           Altern : Living =     30.0 : 1.0\n",
      "      contains(improves) = True           Altern : Living =     30.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "#obtain feature sets for all movie reviews\n",
    "featuresets_journey = [(get_document_features_journey(d,word_features_journey), c) for (d,c) in documents_journey]\n",
    "\n",
    "#split into train and test set (you can experiment with distribution here) 100 - 100 og\n",
    "train_set_journey, test_set_journey = featuresets_journey[200:], featuresets_journey[:100]\n",
    "\n",
    "#instantiate classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set_journey)\n",
    "\n",
    "#print accuracy and most informative features\n",
    "print(nltk.classify.accuracy(classifier, test_set_journey)) \n",
    "\n",
    "classifier.show_most_informative_features(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of sample review:  Living with diabetes - Nutrition\n"
     ]
    }
   ],
   "source": [
    "sample_review = \"My doctor told me to start running and go on a diet\"\n",
    "\n",
    "#get features specific to the input text\n",
    "sample_features = {word:True for word in sample_review.split()}\n",
    "\n",
    "\n",
    "sample_review_doc_feats = get_document_features_journey(sample_review.split(),sample_features)\n",
    "\n",
    "\n",
    "#print('Sample review features: \\n\\n',sample_review_doc_feats)\n",
    "\n",
    "print('result of sample review: ', classifier.classify(sample_review_doc_feats))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8f61be024eba58adef938c9aa1e29e02cb3dece83a5348b1a2dafd16a070453"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

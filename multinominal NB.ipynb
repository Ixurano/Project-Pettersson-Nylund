{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "import random\n",
    "from prettytable import PrettyTable\n",
    "import textwrap \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import excel with pandas Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_emotions = pd.read_excel('Diabetes-classification.xlsx', sheet_name ='Emotions')\n",
    "\n",
    "# Preparing dataset\n",
    "X = df_emotions.loc[:,'discussion_text']\n",
    "y = df_emotions.loc[:,'Label']\n",
    "# removes all duplicates from list \n",
    "Labels = list(dict.fromkeys(y)) \n",
    "# puts discussion_text to a str and tokenize it\n",
    "raw_text = df_emotions['discussion_text'].str.cat()\n",
    "tokens = nltk.word_tokenize(raw_text)\n",
    "text = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinominal NB classifer for Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sadness\n",
      "Trust\n",
      "+------------------------------------------+---------+\n",
      "|             Discussion text              | Emotion |\n",
      "+------------------------------------------+---------+\n",
      "| I'm,such,a,geek..,Ever,since,I,watched,a | Sadness |\n",
      "| ,video,describing,the,biochemistry,of,fr |         |\n",
      "| uctose,in,the,body,I,rarely,give,juice.. |         |\n",
      "| ,Fructose,triggers,a,cascade,of,reaction |         |\n",
      "| s,that,lead,to,obesity,,cardiovascular,d |         |\n",
      "| isease,,type,2,diabetes,,among,other,thi |         |\n",
      "|  ngs....,and,juice,has,way,too,much,of   |         |\n",
      "|                                          |         |\n",
      "|                                          |         |\n",
      "| But,when,foods,are,high,in,sugar,,you're |  Trust  |\n",
      "| ,body,can't,use,it,all,at,once..,Sugar,g |         |\n",
      "| ets,broken,down,too,quickly..,Your,pancr |         |\n",
      "| eas,releases,extra,insulin,,which,you,be |         |\n",
      "| come,desensitized,to,over,time,(type,2,d |         |\n",
      "| iabetes)..,You,get,a,sugar,rush,,and,the |         |\n",
      "|          n,the,excess,is,stored          |         |\n",
      "|                                          |         |\n",
      "|                                          |         |\n",
      "+------------------------------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "# the reviews will be stored as document pairs of words and category\n",
    "X_list_of_words = [sentence.split(\" \") for sentence in X]\n",
    "documents = list(zip(X_list_of_words, y))\n",
    "\n",
    "#give random order to the documents\n",
    "random.shuffle(documents)\n",
    "\n",
    "tab = PrettyTable(['Discussion text', 'Emotion'])\n",
    "tab.horizontal_char = '-'\n",
    "\n",
    "for (doc, cat) in documents[0:2]:\n",
    "    feats = textwrap.fill(','.join(doc[:50]), width=40)\n",
    "    tab.add_row([ feats, cat])\n",
    "    tab.add_row([ '\\n', '\\n'])\n",
    "    print(cat)\n",
    "\n",
    "print(tab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words from emotion corpus:  276377\n",
      "most freq words:  [('think', 398), ('other', 398), ('does', 393), ('many', 389), ('only', 387), ('day', 385), ('time', 383), ('much', 380), ('help', 379), ('risk', 376)]\n",
      "word_features[:25]:  ['i', '..', 'and', 'the', 'to', 'a', 'of', 'diabetes', '2', 'type', 'is', 'my', 'that', 'have', 'in', 'it', 'with', 'for', 'you', 'was', 'on', 'as', 'not', 'but', ')']\n"
     ]
    }
   ],
   "source": [
    "print('total words from emotion corpus: ', len(text))\n",
    "\n",
    "# load all the words in freq distribution\n",
    "all_words = nltk.FreqDist(w.lower() for w in text)\n",
    "\n",
    "#construct a list of the 2000 most frequent words in the overall corpus (you can try with other numbers as well)\n",
    "most_freq_words = all_words.most_common(2000)\n",
    "print('most freq words: ', most_freq_words[100:110])\n",
    "\n",
    "word_features = [word for (word, count) in most_freq_words]\n",
    "print('word_features[:25]: ', word_features[:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed document features, printing the first 25 features \n",
      "\n",
      " {'contains(i)': True, 'contains(..)': True, 'contains(and)': True, 'contains(the)': True, 'contains(to)': True, 'contains(a)': True, 'contains(of)': True, 'contains(diabetes)': True, 'contains(2)': True, 'contains(type)': True, 'contains(is)': True, 'contains(my)': True, 'contains(that)': True, 'contains(have)': True, 'contains(in)': True, 'contains(it)': True, 'contains(with)': True, 'contains(for)': True, 'contains(you)': True, 'contains(was)': True, 'contains(on)': True, 'contains(as)': True, 'contains(not)': True, 'contains(but)': True, 'contains())': True}\n"
     ]
    }
   ],
   "source": [
    "def get_document_features(document, doc_features):\n",
    "    \"\"\"\n",
    "        This function will convert given document into a feature set.\n",
    "        Note that we need to add the feature set that is relevant to the document we are inputting\n",
    "        \n",
    "    \"\"\"\n",
    "    #checking whether a word occurs in a set is much faster than checking whether it occurs in a list \n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    \n",
    "    #the feaures dict will consist of words as keys and boolean value of whether they exist in the document\n",
    "    for word in doc_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "\n",
    "# test code for the above function\n",
    "#words_doc = movie_reviews.words('pos/cv957_8737.txt')\n",
    "words_doc = text\n",
    "\n",
    "feat_dict = get_document_features(words_doc, word_features)\n",
    "\n",
    "feat_dict_25 = {k: feat_dict[k] for k in list(feat_dict.keys())[:25]}\n",
    "print('transformed document features, printing the first 25 features \\n\\n', feat_dict_25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18\n",
      "Most Informative Features\n",
      "         contains(bacon) = True            Anger : Trust  =     23.2 : 1.0\n",
      "          contains(hold) = True            Anger : Trust  =     23.2 : 1.0\n",
      "    contains(production) = True            Anger : Trust  =     23.2 : 1.0\n",
      "          contains(rare) = True            Anger : Trust  =     23.2 : 1.0\n",
      "         contains(crazy) = True             Fear : Trust  =     20.9 : 1.0\n",
      "        contains(stated) = True             Fear : Trust  =     20.9 : 1.0\n",
      "         contains(story) = True            Anger : Antici =     18.5 : 1.0\n",
      "            contains(ie) = True             Fear : Antici =     16.6 : 1.0\n",
      "  contains(intervention) = True             Fear : Antici =     16.6 : 1.0\n",
      "       contains(suppose) = True             Fear : Trust  =     14.9 : 1.0\n",
      "          contains(2006) = True            Anger : Trust  =     13.9 : 1.0\n",
      "            contains(32) = True            Anger : Trust  =     13.9 : 1.0\n",
      "            contains(49) = True            Anger : Trust  =     13.9 : 1.0\n",
      "        contains(action) = True            Anger : Trust  =     13.9 : 1.0\n",
      "         contains(belly) = True            Anger : Trust  =     13.9 : 1.0\n",
      "         contains(black) = True            Anger : Trust  =     13.9 : 1.0\n",
      "         contains(eaten) = True            Anger : Trust  =     13.9 : 1.0\n",
      " contains(empagliflozin) = True            Anger : Trust  =     13.9 : 1.0\n",
      "          contains(hate) = True            Anger : Trust  =     13.9 : 1.0\n",
      "         contains(hba1c) = True            Anger : Trust  =     13.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "#obtain feature sets for all movie reviews\n",
    "featuresets = [(get_document_features(d,word_features), c) for (d,c) in documents]\n",
    "\n",
    "#split into train and test set (you can experiment with distribution here)\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "\n",
    "#instantiate classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "#print accuracy and most informative features\n",
    "print(nltk.classify.accuracy(classifier, test_set)) \n",
    "\n",
    "classifier.show_most_informative_features(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of sample review:  Joy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_review = 'I think I got rid of my sicknesss and feel happy'\n",
    "\n",
    "#get features specific to the input text\n",
    "sample_features = {word:True for word in sample_review.split()}\n",
    "\n",
    "\n",
    "sample_review_doc_feats = get_document_features(sample_review.split(),sample_features)\n",
    "\n",
    "\n",
    "#print('Sample review features: \\n\\n',sample_review_doc_feats)\n",
    "\n",
    "print('result of sample review: ', classifier.classify(sample_review_doc_feats))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loads in Patient Journey labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_patient = pd.read_excel('Diabetes-classification.xlsx', sheet_name='Patient-journey') # Reads in excel\n",
    "#print(df_patient.head(), df_patient.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8f61be024eba58adef938c9aa1e29e02cb3dece83a5348b1a2dafd16a070453"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tommy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "import random\n",
    "from prettytable import PrettyTable\n",
    "import textwrap \n",
    "import numpy as np\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import excel with pandas Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_emotions = pd.read_excel('Diabetes-classification.xlsx', sheet_name ='Emotions')\n",
    "\n",
    "# Preparing dataset\n",
    "x_emotion = df_emotions.loc[:,'discussion_text']\n",
    "y_emotion = df_emotions.loc[:,'Label']\n",
    "new_dataframe = list(zip(y_emotion, x_emotion))\n",
    "new_df = pd.DataFrame(new_dataframe, columns=['Label', 'Discussion_text'])\n",
    "\n",
    "# removes all duplicates from list \n",
    "Labels_emotion = list(dict.fromkeys(y_emotion)) \n",
    "# puts discussion_text to a str and tokenize it\n",
    "raw_text_emotion = df_emotions['discussion_text'].str.cat()\n",
    "tokens_emotion = nltk.word_tokenize(raw_text_emotion)\n",
    "tokens_emotion_filtered = [word for word in tokens_emotion if word.isalnum()]\n",
    "text_emotion = nltk.Text(tokens_emotion_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinominal NB classifer for Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sadness\n",
      "Joy\n",
      "+------------------------------------------+---------+\n",
      "|             Discussion text              | Emotion |\n",
      "+------------------------------------------+---------+\n",
      "| I,want,to,echo,Lyndol's,suggestion,to,ta | Sadness |\n",
      "| lk,to,your,doctor,about,metformin--that' |         |\n",
      "| s,what,most,T2s,start,out,with..,Do,you, |         |\n",
      "| know,if,there's,a,particular,reason,that |         |\n",
      "| ,your,doctor,prescribed,glucotrol?.,Here |         |\n",
      "| 's,a,link,to,a,chart,with,info,about,var |         |\n",
      "| ious,T2,oral,meds:,http://www.joslin.org |         |\n",
      "| /info/oral_diabetes_medicatio,ns_summary |         |\n",
      "|         _chart.html,I,don't,know         |         |\n",
      "|                                          |         |\n",
      "|                                          |         |\n",
      "| For,anyone,who,tells,you,that,the,brain, |   Joy   |\n",
      "| needs,carbohydrates,as,its,source,of,ene |         |\n",
      "| rgy,,tell,them,that,research,has,shown,t |         |\n",
      "| hat,most,of,the,brain,can,switch,to,usin |         |\n",
      "| g,fats,as,its,source,of,energy,instead,, |         |\n",
      "| and,the,liver,can,convert,proteins,to,gl |         |\n",
      "|           ucose,fast,enough,to           |         |\n",
      "|                                          |         |\n",
      "|                                          |         |\n",
      "+------------------------------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "# the reviews will be stored as document pairs of words and category\n",
    "X_list_of_words = [sentence.split(\" \") for sentence in x_emotion]\n",
    "documents = list(zip(X_list_of_words, y_emotion))\n",
    "\n",
    "#give random order to the documents\n",
    "random.shuffle(documents)\n",
    "\n",
    "tab = PrettyTable(['Discussion text', 'Emotion'])\n",
    "tab.horizontal_char = '-'\n",
    "\n",
    "for (doc, cat) in documents[0:2]:\n",
    "    feats = textwrap.fill(','.join(doc[:50]), width=40)\n",
    "    tab.add_row([ feats, cat])\n",
    "    tab.add_row([ '\\n', '\\n'])\n",
    "    print(cat)\n",
    "\n",
    "print(tab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words from emotion corpus:  248961\n",
      "most freq words:  [('women', 58), ('needs', 58), ('true', 57), ('plan', 57), ('appointment', 57), ('cure', 57), ('8', 57), ('major', 56), ('oral', 56), ('energy', 56), ('active', 56), ('stay', 56), ('newly', 56), ('above', 56), ('instead', 56), ('water', 56), ('real', 55), ('love', 55), ('kind', 55), ('site', 55), ('mg', 55), ('grains', 54), ('further', 54), ('night', 54), ('become', 54), ('mother', 54), ('learn', 54), ('factor', 54), ('add', 53), ('goes', 53), ('example', 53), ('readings', 53), ('taken', 53), ('current', 53), ('reducing', 53), ('personal', 53), ('prescribed', 53), ('mom', 53), ('doc', 52), ('members', 52), ('causing', 52), ('questions', 52), ('interesting', 52), ('bmi', 52), ('thyroid', 52), ('cases', 52), ('association', 51), ('kidney', 51), ('beta', 51), ('asked', 51), ('must', 51), ('50', 51), ('hospital', 51), ('small', 51), ('huge', 51), ('talk', 50), ('longer', 50), ('generally', 50), ('habits', 50), ('nhs', 50), ('syndrome', 50), ('bread', 49), ('agree', 49), ('12', 49), ('matter', 49), ('including', 49), ('reduced', 49), ('talking', 49), ('heard', 49), ('dose', 49), ('fats', 49), ('lack', 48), ('stomach', 48), ('wanted', 48), ('reversed', 48), ('choices', 48), ('metabolic', 48), ('call', 48), ('suggest', 48), ('carbohydrates', 48), ('starting', 48), ('hear', 48), ('understanding', 48), ('completely', 47), ('recent', 47), ('unless', 47), ('despite', 47), ('simple', 47), ('system', 47), ('fatty', 47), ('100', 47), ('gets', 47), ('exactly', 47), ('general', 47), ('total', 47), ('avoid', 47), ('aware', 46), ('mentioned', 46), ('felt', 46), ('short', 46)]\n",
      "word_features[:25]:  ['i', 'and', 'the', 'to', 'a', 'of', 'diabetes', '2', 'type', 'is', 'my', 'that', 'have', 'in', 'it', 'with', 'for', 'you', 'was', 'on', 'as', 'not', 'but', 'this', 'are']\n"
     ]
    }
   ],
   "source": [
    "print('total words from emotion corpus: ', len(text_emotion))\n",
    "\n",
    "# load all the words in freq distribution\n",
    "all_words = nltk.FreqDist(w.lower() for w in text_emotion)\n",
    "\n",
    "#construct a list of the 2000 most frequent words in the overall corpus (you can try with other numbers as well)\n",
    "most_freq_words = all_words.most_common(10000)\n",
    "print('most freq words: ', most_freq_words[500:600])\n",
    "\n",
    "word_features = [word for (word, count) in most_freq_words]\n",
    "print('word_features[:25]: ', word_features[:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed document features, printing the first 25 features \n",
      "\n",
      " {'contains(i)': True, 'contains(and)': True, 'contains(the)': True, 'contains(to)': True, 'contains(a)': True, 'contains(of)': True, 'contains(diabetes)': True, 'contains(2)': True, 'contains(type)': True, 'contains(is)': True, 'contains(my)': True, 'contains(that)': True, 'contains(have)': True, 'contains(in)': True, 'contains(it)': True, 'contains(with)': True, 'contains(for)': True, 'contains(you)': True, 'contains(was)': True, 'contains(on)': True, 'contains(as)': True, 'contains(not)': True, 'contains(but)': True, 'contains(this)': True, 'contains(are)': True}\n"
     ]
    }
   ],
   "source": [
    "def get_document_features(document, doc_features):\n",
    "    \"\"\"\n",
    "        This function will convert given document into a feature set.\n",
    "        Note that we need to add the feature set that is relevant to the document we are inputting\n",
    "        \n",
    "    \"\"\"\n",
    "    #checking whether a word occurs in a set is much faster than checking whether it occurs in a list \n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    \n",
    "    #the feaures dict will consist of words as keys and boolean value of whether they exist in the document\n",
    "    for word in doc_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "\n",
    "# test code for the above function\n",
    "#words_doc = movie_reviews.words('pos/cv957_8737.txt')\n",
    "words_doc = text_emotion\n",
    "\n",
    "feat_dict = get_document_features(words_doc, word_features)\n",
    "\n",
    "feat_dict_25 = {k: feat_dict[k] for k in list(feat_dict.keys())[:25]}\n",
    "print('transformed document features, printing the first 25 features \\n\\n', feat_dict_25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18\n",
      "Most Informative Features\n",
      "         contains(bacon) = True            Anger : Trust  =     23.4 : 1.0\n",
      "          contains(hold) = True            Anger : Trust  =     23.4 : 1.0\n",
      "         contains(lover) = True            Anger : Trust  =     23.4 : 1.0\n",
      "    contains(production) = True            Anger : Trust  =     23.4 : 1.0\n",
      "          contains(rare) = True            Anger : Trust  =     23.4 : 1.0\n",
      "         contains(shift) = True            Anger : Trust  =     23.4 : 1.0\n",
      "        contains(stated) = True             Fear : Trust  =     20.9 : 1.0\n",
      "           contains(2nd) = True            Anger : Antici =     18.8 : 1.0\n",
      "    contains(incredibly) = True            Anger : Antici =     18.8 : 1.0\n",
      "    contains(motivation) = True            Anger : Antici =     18.8 : 1.0\n",
      "    contains(responding) = True            Anger : Antici =     18.8 : 1.0\n",
      "          contains(bike) = True             Fear : Antici =     16.7 : 1.0\n",
      "            contains(ie) = True             Fear : Antici =     16.7 : 1.0\n",
      "  contains(intervention) = True             Fear : Antici =     16.7 : 1.0\n",
      "            contains(38) = True             Fear : Trust  =     14.9 : 1.0\n",
      "            contains(bc) = True             Fear : Trust  =     14.9 : 1.0\n",
      "      contains(controls) = True             Fear : Trust  =     14.9 : 1.0\n",
      "         contains(crazy) = True             Fear : Trust  =     14.9 : 1.0\n",
      "         contains(deals) = True             Fear : Trust  =     14.9 : 1.0\n",
      "        contains(skinny) = True             Fear : Trust  =     14.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "#obtain feature sets for all movie reviews\n",
    "featuresets = [(get_document_features(d,word_features), c) for (d,c) in documents]\n",
    "\n",
    "#split into train and test set (you can experiment with distribution here) 100 - 100 og\n",
    "train_set, test_set = featuresets[150:], featuresets[:150]\n",
    "\n",
    "#instantiate classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "#print accuracy and most informative features\n",
    "print(nltk.classify.accuracy(classifier, test_set)) \n",
    "\n",
    "classifier.show_most_informative_features(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of sample review:  Joy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_review = \"I think i got rid of my sickness and feel happy\"\n",
    "\n",
    "#get features specific to the input text\n",
    "sample_features = {word:True for word in sample_review.split()}\n",
    "\n",
    "\n",
    "sample_review_doc_feats = get_document_features(sample_review.split(),sample_features)\n",
    "\n",
    "\n",
    "#print('Sample review features: \\n\\n',sample_review_doc_feats)\n",
    "\n",
    "print('result of sample review: ', classifier.classify(sample_review_doc_feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loads in Patient Journey labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_patient = pd.read_excel('Diabetes-classification.xlsx', sheet_name='Patient-journey') # Reads in excel\n",
    "\n",
    "# Preparing dataset\n",
    "x_journey = df_patient.loc[:,'discussion_text']\n",
    "y_journey = df_patient.loc[:,'Label']\n",
    "# removes all duplicates from list \n",
    "Labels_journey = list(dict.fromkeys(y_journey)) \n",
    "# puts discussion_text to a str and tokenize it\n",
    "raw_text_journey = df_patient['discussion_text'].str.cat()\n",
    "tokens_journey = nltk.word_tokenize(raw_text_journey)\n",
    "text_journey = nltk.Text(tokens_journey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinical Treatment\n",
      "Clinical Treatment\n",
      "+------------------------------------------+--------------------+\n",
      "|             Discussion text              |      Emotion       |\n",
      "+------------------------------------------+--------------------+\n",
      "| Hello,i,am,new,here..,I,want,to,tell,you | Clinical Treatment |\n",
      "| ,that,2,members,in,my,family,diagonesed, |                    |\n",
      "| by,type,2,diabetes..,what,precautions,we |                    |\n",
      "| ,need,to,concern,along,with,medical,pres |                    |\n",
      "|                cription,?                |                    |\n",
      "|                                          |                    |\n",
      "|                                          |                    |\n",
      "| Hello,everyone,,My,name,is,Nate,,I,am,a, | Clinical Treatment |\n",
      "| 25,year,old,Male,and,I,was,diagnosed,wit |                    |\n",
      "| h,Type,2,Diabetes,when,I,was,14..,I,was, |                    |\n",
      "| fairly,heavy,at,that,age,(250Lbs),and,ha |                    |\n",
      "| d,an,A1C,around,12..,I,was,put,on,insuli |                    |\n",
      "|           n,(one,unit,of,fast            |                    |\n",
      "|                                          |                    |\n",
      "|                                          |                    |\n",
      "+------------------------------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# the reviews will be stored as document pairs of words and category\n",
    "X_list_of_words_journey = [sentence.split(\" \") for sentence in x_journey]\n",
    "documents_journey = list(zip(X_list_of_words_journey, y_journey))\n",
    "\n",
    "#give random order to the documents\n",
    "random.shuffle(documents_journey)\n",
    "\n",
    "tab = PrettyTable(['Discussion text', 'Emotion'])\n",
    "tab.horizontal_char = '-'\n",
    "\n",
    "for (doc, cat) in documents_journey[0:2]:\n",
    "    feats = textwrap.fill(','.join(doc[:50]), width=40)\n",
    "    tab.add_row([ feats, cat])\n",
    "    tab.add_row([ '\\n', '\\n'])\n",
    "    print(cat)\n",
    "\n",
    "print(tab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words from emotion corpus:  116721\n",
      "most freq words:  [('his', 165), ('exercise', 165), ('only', 159), ('she', 159), ('time', 159), ('well', 157), ('any', 157), ('glucose', 156), ('then', 155), ('disease', 154)]\n",
      "word_features[:25]:  ['..', 'i', 'and', 'the', 'to', 'a', 'of', 'diabetes', '2', 'type', 'is', 'in', 'my', 'that', 'with', 'have', 'for', 'it', 'you', 'was', 'on', 'as', 'are', ')', '.']\n"
     ]
    }
   ],
   "source": [
    "print('total words from emotion corpus: ', len(text_journey))\n",
    "\n",
    "# load all the words in freq distribution\n",
    "all_words_journey = nltk.FreqDist(w.lower() for w in text_journey)\n",
    "\n",
    "#construct a list of the 2000 most frequent words in the overall corpus (you can try with other numbers as well)\n",
    "most_freq_words_journey = all_words_journey.most_common(6000)\n",
    "print('most freq words: ', most_freq_words_journey[100:110])\n",
    "\n",
    "word_features_journey = [word for (word, count) in most_freq_words_journey]\n",
    "print('word_features[:25]: ', word_features_journey[:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed document features, printing the first 25 features \n",
      "\n",
      " {'contains(..)': True, 'contains(i)': True, 'contains(and)': True, 'contains(the)': True, 'contains(to)': True, 'contains(a)': True, 'contains(of)': True, 'contains(diabetes)': True, 'contains(2)': True, 'contains(type)': True, 'contains(is)': True, 'contains(in)': True, 'contains(my)': True, 'contains(that)': True, 'contains(with)': True, 'contains(have)': True, 'contains(for)': True, 'contains(it)': True, 'contains(you)': True, 'contains(was)': True, 'contains(on)': True, 'contains(as)': True, 'contains(are)': True, 'contains())': True, 'contains(.)': True}\n"
     ]
    }
   ],
   "source": [
    "def get_document_features_journey(documents_journey, doc_features):\n",
    "    \"\"\"\n",
    "        This function will convert given document into a feature set.\n",
    "        Note that we need to add the feature set that is relevant to the document we are inputting\n",
    "        \n",
    "    \"\"\"\n",
    "    #checking whether a word occurs in a set is much faster than checking whether it occurs in a list \n",
    "    document_words = set(documents_journey)\n",
    "    features = {}\n",
    "    \n",
    "    #the feaures dict will consist of words as keys and boolean value of whether they exist in the document\n",
    "    for word in doc_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "\n",
    "# test code for the above function\n",
    "#words_doc = movie_reviews.words('pos/cv957_8737.txt')\n",
    "words_doc = text_journey\n",
    "\n",
    "feat_dict = get_document_features(words_doc, word_features_journey)\n",
    "\n",
    "feat_dict_25 = {k: feat_dict[k] for k in list(feat_dict.keys())[:25]}\n",
    "print('transformed document features, printing the first 25 features \\n\\n', feat_dict_25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47\n",
      "Most Informative Features\n",
      "      contains(exercise) = True           Living : Living =     46.0 : 1.0\n",
      "    contains(colleagues) = True           Altern : Living =     35.7 : 1.0\n",
      "       contains(studies) = True           Altern : Living =     29.4 : 1.0\n",
      "    contains(treatments) = True           Altern : Living =     29.4 : 1.0\n",
      "            contains(35) = True           Altern : Living =     25.5 : 1.0\n",
      "        contains(accept) = True           Altern : Living =     25.5 : 1.0\n",
      "        contains(acidic) = True           Altern : Living =     25.5 : 1.0\n",
      "      contains(addition) = True           Altern : Living =     25.5 : 1.0\n",
      "    contains(additional) = True           Altern : Living =     25.5 : 1.0\n",
      "        contains(agents) = True           Altern : Living =     25.5 : 1.0\n",
      "      contains(approved) = True           Altern : Living =     25.5 : 1.0\n",
      "        contains(bitter) = True           Altern : Living =     25.5 : 1.0\n",
      "         contains(bones) = True           Altern : Living =     25.5 : 1.0\n",
      "        contains(bought) = True           Altern : Living =     25.5 : 1.0\n",
      "        contains(broken) = True           Altern : Living =     25.5 : 1.0\n",
      "        contains(charge) = True           Altern : Living =     25.5 : 1.0\n",
      "    contains(conclusion) = True           Altern : Living =     25.5 : 1.0\n",
      "   contains(development) = True           Altern : Living =     25.5 : 1.0\n",
      "      contains(examined) = True           Altern : Living =     25.5 : 1.0\n",
      "     contains(expensive) = True           Altern : Living =     25.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "#obtain feature sets for all movie reviews\n",
    "featuresets_journey = [(get_document_features_journey(d,word_features_journey), c) for (d,c) in documents_journey]\n",
    "\n",
    "#split into train and test set (you can experiment with distribution here) 100 - 100 og\n",
    "train_set_journey, test_set_journey = featuresets_journey[200:], featuresets_journey[:100]\n",
    "\n",
    "#instantiate classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set_journey)\n",
    "\n",
    "#print accuracy and most informative features\n",
    "print(nltk.classify.accuracy(classifier, test_set_journey)) \n",
    "\n",
    "classifier.show_most_informative_features(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of sample review:  Living with diabetes - Nutrition\n"
     ]
    }
   ],
   "source": [
    "sample_review = \"My doctor told me to start running and go on a diet\"\n",
    "\n",
    "#get features specific to the input text\n",
    "sample_features = {word:True for word in sample_review.split()}\n",
    "\n",
    "\n",
    "sample_review_doc_feats = get_document_features_journey(sample_review.split(),sample_features)\n",
    "\n",
    "\n",
    "#print('Sample review features: \\n\\n',sample_review_doc_feats)\n",
    "\n",
    "print('result of sample review: ', classifier.classify(sample_review_doc_feats))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8f61be024eba58adef938c9aa1e29e02cb3dece83a5348b1a2dafd16a070453"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
